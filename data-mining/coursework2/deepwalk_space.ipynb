{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the dataset from https://densitydesign.github.io/strumentalia-seealsology/\n",
    "\n",
    "__Steps to download:__\n",
    "\n",
    "a) Enter the following links:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Space_research\n",
    "\n",
    "https://en.wikipedia.org/wiki/Space_Race\n",
    "\n",
    "https://en.wikipedia.org/wiki/Space_exploration\n",
    "\n",
    "b) Download the TSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('F:/data/course-2/edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    " \n",
    "def generate_random_str(randomlength=16):\n",
    "  \"\"\"\n",
    "  生成一个指定长度的随机字符串，其中\n",
    "  string.digits=0123456789\n",
    "  string.ascii_letters=abcdefghigklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "  \"\"\"\n",
    "  str_list = [random.choice(string.digits + string.ascii_letters) for i in range(randomlength)]\n",
    "  random_str = ''.join(str_list)\n",
    "  return random_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_map = dict([])\n",
    "for i in range(31136):\n",
    "    key_map[i] = generate_random_str(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31136"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = np.array(list(key_map.values()))\n",
    "len(np.unique(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target\n",
       "0       0       2\n",
       "1       0       1\n",
       "2       1       0\n",
       "3       7       8\n",
       "4       8       7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df['source'].astype('object')\n",
    "df['target'] = df['target'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source    object\n",
      "target    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W87O1XyaLZC0b8Q</td>\n",
       "      <td>CBE0Py0IGMGI5uu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W87O1XyaLZC0b8Q</td>\n",
       "      <td>vclniGH7o0Hhf5p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vclniGH7o0Hhf5p</td>\n",
       "      <td>W87O1XyaLZC0b8Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DRJmfVcgO24PIkm</td>\n",
       "      <td>T8bDqqVJbwTYf2Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T8bDqqVJbwTYf2Q</td>\n",
       "      <td>DRJmfVcgO24PIkm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source           target\n",
       "0  W87O1XyaLZC0b8Q  CBE0Py0IGMGI5uu\n",
       "1  W87O1XyaLZC0b8Q  vclniGH7o0Hhf5p\n",
       "2  vclniGH7o0Hhf5p  W87O1XyaLZC0b8Q\n",
       "3  DRJmfVcgO24PIkm  T8bDqqVJbwTYf2Q\n",
       "4  T8bDqqVJbwTYf2Q  DRJmfVcgO24PIkm"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "edges = df.values\n",
    "for i in range(len(edges)):\n",
    "    edges[i, 0] = key_map[edges[i, 0]]\n",
    "    edges[i, 1] = key_map[edges[i, 1]]\n",
    "print(edges.dtype)\n",
    "new_df = pd.DataFrame(columns=['source', 'target'])\n",
    "new_df['source'] = edges[:, 0]\n",
    "new_df['target'] = edges[:, 1]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source    object\n",
      "target    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(new_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_graph(edges, nodes):\n",
    "        \"\"\"\n",
    "            Create graph from the edges matrix and nodes vectors.\n",
    "\n",
    "            Args:\n",
    "                edges(np.ndarray): shape of (n_edges, 2) or shape of (n_edges, 3).\n",
    "                nodes(np.ndarray): shape of (n_nodes, ).\n",
    "            Returns:\n",
    "                graph(networkx.Graph): a networkx Graph instance.\n",
    "            \"\"\"\n",
    "        with_weight = edges.shape[1] == 3  # the 3rd dimension is edge weight.\n",
    "        graph = nx.Graph()\n",
    "        graph.add_nodes_from(nodes.tolist())\n",
    "        for edge_i in edges:\n",
    "            node1 = edge_i[0]\n",
    "            node2 = edge_i[1]\n",
    "            if with_weight:\n",
    "                weight = edge_i[2]\n",
    "                graph.add_edge(node1, node2, weight)\n",
    "            else:\n",
    "                graph.add_edge(node1, node2)\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31136\n"
     ]
    }
   ],
   "source": [
    "nodes = np.unique(edges)\n",
    "print(len(nodes))\n",
    "G = _create_graph(edges, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|███████████████████████████████████████| 31136/31136 [01:05<00:00, 474.35it/s]\n"
     ]
    }
   ],
   "source": [
    "node2vec = Node2Vec(G, dimensions=100, walk_length=20, num_walks=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an undirected graph\n",
    "G=nx.from_pandas_edgelist(new_df, \"source\", \"target\", edge_attr=True, create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31136"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G) # number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate random walk sequences of nodes\n",
    "def get_randomwalk(node, path_length):\n",
    "    \n",
    "    random_walk = [node]\n",
    "    \n",
    "    for i in range(path_length-1):\n",
    "        temp = list(G.neighbors(node))\n",
    "        temp = list(set(temp) - set(random_walk))    \n",
    "        if len(temp) == 0:\n",
    "            break\n",
    "\n",
    "        random_node = random.choice(temp)\n",
    "        random_walk.append(random_node)\n",
    "        node = random_node\n",
    "        \n",
    "    return random_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kOZWLuxXQsOqCSY',\n",
       " 'JdFiRhSs4Yl5tvc',\n",
       " 'KFf8n77getzlIMo',\n",
       " 'fu1t5i4wDijMUmv',\n",
       " 'FKuQ5RyM8N5VHIR',\n",
       " 'fm4wtP2zJpgd7IH',\n",
       " 'ircAuiGTNZRMsAo',\n",
       " '9PhElRJYuh7ni1m',\n",
       " 'ytQz1XNpRe4mznj',\n",
       " 'gCLlkRazpGjNfUR']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_randomwalk('kOZWLuxXQsOqCSY', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 31136/31136 [00:09<00:00, 3222.79it/s]\n"
     ]
    }
   ],
   "source": [
    "all_nodes = list(G.nodes())\n",
    "\n",
    "random_walks = []\n",
    "\n",
    "for n in tqdm(all_nodes):\n",
    "    for i in range(5):\n",
    "        random_walks.append(get_randomwalk(n,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155680"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of sequences\n",
    "len(random_walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model\n",
    "model = Word2Vec(window = 4, sg = 1, hs = 0,\n",
    "                 negative = 10, # for negative sampling\n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "\n",
    "model.build_vocab(random_walks, progress_per=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31135180, 31135180)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(random_walks, total_examples = model.corpus_count, epochs=20, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=31136, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reduced-gravity aircraft', 0.9756266474723816),\n",
       " ('micro-g environment', 0.9612352252006531),\n",
       " ('spaceflight osteopenia', 0.8710659742355347),\n",
       " ('microgravity university', 0.8698078393936157),\n",
       " ('space flight participant', 0.8578461408615112),\n",
       " ('space adaptation syndrome', 0.8436012268066406),\n",
       " ('space tourism society', 0.8100888729095459),\n",
       " ('lagrange point colonization', 0.7876768112182617),\n",
       " ('stanford torus', 0.7843056321144104),\n",
       " ('lists of space programs', 0.7734896540641785)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find top n similar nodes\n",
    "model.similar_by_word('astronaut training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ['lunar escape systems','soviet moonshot', 'soyuz 7k-l1', 'moon landing',\n",
    "         'space food', 'food systems on space exploration missions', 'meal, ready-to-eat',\n",
    "         'space law', 'metalaw', 'moon treaty', 'legal aspects of computing',\n",
    "         'astronaut training', 'reduced-gravity aircraft', 'space adaptation syndrome', 'micro-g environment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = list(key_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nodes(word_list):\n",
    "    X = model[word_list]\n",
    "    \n",
    "    # reduce dimensions to 2\n",
    "    pca = PCA(n_components=2)\n",
    "    result = pca.fit_transform(X)\n",
    "    print(result)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(12,9))\n",
    "    # create a scatter plot of the projection\n",
    "    plt.scatter(result[:, 0], result[:, 1])    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hppc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.51724154  0.15543737 -0.40485814 ... -0.1350585  -0.79905295\n",
      "  -0.44472983]\n",
      " [-0.24738924 -0.01353899 -0.35022303 ... -0.34508088 -0.96476346\n",
      "  -0.11683018]\n",
      " [ 0.10339013  0.2314968  -0.5118003  ...  0.2793765   0.093804\n",
      "  -0.00935603]\n",
      " ...\n",
      " [ 0.5890967  -0.07106898 -0.01868995 ...  0.03065697  0.1506573\n",
      "   0.77508956]\n",
      " [ 0.6838051  -0.05078315  0.19423343 ...  0.07558585  0.03166173\n",
      "   0.6298917 ]\n",
      " [ 0.5898434  -0.19957133 -0.01377609 ...  0.04623912  0.36336508\n",
      "   0.85478103]]\n"
     ]
    }
   ],
   "source": [
    "X = model[terms]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 1 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n",
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def convert_with_gt(communities, ground_truth):\n",
    "    gt_col1 = ground_truth[:, 0].tolist()\n",
    "    n_communities = np.unique(communities)\n",
    "    communities_dict = dict([])\n",
    "    for i in range(len(n_communities)):\n",
    "        community = n_communities[i]\n",
    "        nodes = np.where(communities==community)[0].tolist()\n",
    "        communities_dict[community] = nodes\n",
    "    res = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "    print(communities_dict.keys())\n",
    "    for c in communities_dict.keys():\n",
    "        nodes = communities_dict[c]\n",
    "        gt = []\n",
    "        for i in range(len(nodes)):\n",
    "            node = nodes[i]\n",
    "            if node in gt_col1:\n",
    "                idx = np.where(node == ground_truth[:, 0])\n",
    "                category = ground_truth[idx, 1][0][0]\n",
    "                gt.append(category)\n",
    "        gt = np.array(gt, dtype=np.int64)\n",
    "        print(gt)\n",
    "        if len(gt) == 0:\n",
    "            category = 2\n",
    "        else:\n",
    "            category = Counter(gt).most_common()[0][0]\n",
    "        print(category)\n",
    "        res[category] = res[category] + nodes\n",
    "    communities_gt = np.zeros((len(communities), ), dtype=communities.dtype)\n",
    "    for c in res.keys():\n",
    "        nodes = res[c]\n",
    "        for node in nodes:\n",
    "            communities_gt[node] = c  # get community\n",
    "    return communities_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4])\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "2\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "1\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "0\n",
      "[4 4 4 4 4 4 4 4 4 4]\n",
      "4\n",
      "[3 3 3 3 3 3 3 3 3 3]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "ground_truth_path = 'data/ground_truth.csv'\n",
    "ground_truth = pd.read_csv(ground_truth_path)\n",
    "ground_truth = ground_truth.values\n",
    "communities_gt = convert_with_gt(communities, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['id', 'category'])\n",
    "nodes = np.array(list(range(len(nodes))))\n",
    "df['id'] = np.sort(nodes)\n",
    "df['category'] = communities_gt\n",
    "df.to_csv('data/submission6.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981693216855088\n"
     ]
    }
   ],
   "source": [
    "com2 = pd.read_csv('data/submission4.csv')\n",
    "com3 = pd.read_csv('data/submission6.csv')\n",
    "com2 = com2.values[:, 1]\n",
    "com3 = com3.values[:, 1]\n",
    "print(np.sum(com2 == com3) / len(com2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
